PAY_6 = factor(PAY_6, order=TRUE,levels=c(seq(0,9, by = 1))))
# variables clustering
# only use numerical data to do hirerarchical clustering
cor_data = cor(data[,-c(2,3,4,6,7,8,9,10,11,24)])
data_dist = as.dist(cor_data)
# variables clustering
# only use numerical data to do hirerarchical clustering
cor_data = cor(data[,-c(24)])
# variables clustering
# only use numerical data to do hirerarchical clustering
cor_data = cor(data[,-c(2,3,4,6,24)])
# variables clustering
# only use numerical data to do hirerarchical clustering
cor_data = cor(data[,-c(2,3,4,24)])
# variables clustering
# only use numerical data to do hirerarchical clustering
cor_data = cor(data[,-c(2,3,4,6,7,8,9,10,11,24)])
data_dist = as.dist(cor_data)
Msingle = hclust(data_dist, method = "single")
Mcomplete = hclust(data_dist, method = "complete")
Maverage = hclust(data_dist, method = "average")
par(mfrow = c(1, 3))
plot(Msingle)
plot(Mcomplete)
plot(Maverage)
# variables clustering
# only use numerical data to do hierarchical clustering
# use correlation as similarity measure
# variable clustering
data_hc = data[,-c(2,3,4,6,7,8,9,10,11,24)]
cor_data = cor(data_hc)
data_dist = as.dist(cor_data)
Msingle = hclust(data_dist, method = "single")
Mcomplete = hclust(data_dist, method = "complete")
Maverage = hclust(data_dist, method = "average")
# observation clustering
NormX = as.matrix(data_hc)%*%solve(diag(sqrt(diag(var(data_hc)))))
distobs=dist(NormX,method="euclidean")
print(distobs,digits =2)
gc()
setwd("C:/R/big-data/FINAL PROJECT")
plot(Msingle)
plot(Mcomplete)
plot(Maverage)
par(mfrow = c(1, 3))
plot(Msingle)
plot(Mcomplete)
plot(Maverage)
cor_data
mean(data_hc)
data_hc = data[,-c(2,3,4,6,7,8,9,10,11,24)]
data_hc = mean(data_hc)
cor_data = cor(data_hc)
# variables clustering
# only use numerical data to do hierarchical clustering
# use correlation as similarity measure
# variable clustering
data_hc = data[,-c(2,3,4,6,7,8,9,10,11,24)]
cor_data = cor(data_hc)
data_dist = as.dist(cor_data)
Msingle = hclust(data_dist, method = "single")
Mcomplete = hclust(data_dist, method = "complete")
Maverage = hclust(data_dist, method = "average")
par(mfrow = c(1, 3))
plot(Msingle)
plot(Mcomplete)
par(mfrow = c(1, 3))
plot(Msingle)
plot(Mcomplete)
plot(Maverage)
# fit lasso
X = as.matrix(train_data[,1:23])
set.seed(1234)
# split data
idx = sample(1:nrow(data), size=nrow(data)*0.8, replace = FALSE)
train_data = data[idx,]
test_data = data[-idx,]
# initial value
logistic_fit = glm(default ~ ., data = train_data, family = binomial)
summary(logistic_fit)
# library
library(glmnet)
# fit lasso
X = as.matrix(train_data[,1:23])
Y = train_data$default
cv_model = cv.glmnet(X, Y, family = "binomial", alpha = 1)
gmm_model <- Mclust(data[, -24], G = 5)
# Perform GMM clustering
library(mclust)
gmm_model <- Mclust(data[, -24], G = 5)
nrow(data_hc)
# Subset the data by randomly selecting 500 observations
subset_data <- data_hc[sample(nrow(data_hc), 500), ]
# Perform hierarchical clustering on the subset data
hc <- hclust(dist(subset_data))
# Plot the dendrogram
plot(hc, main = "Hierarchical Clustering Dendrogram - Subset Data")
# Subset the data by randomly selecting 500 observations
subset_data <- data_hc[sample(nrow(data_hc), 100), ]
# Perform hierarchical clustering on the subset data
hc <- hclust(dist(subset_data))
# Plot the dendrogram
plot(hc, main = "Hierarchical Clustering Dendrogram - Subset Data")
View(data_hc)
# Plot the dendrogram
cluster_labels <- cutree(hc, k = 3)
data_hc["cluster_labels"] = cluster_labels
data_hc$cluster_labels = cluster_labels
data_hc$cluster_labels <- cluster_labels
# Summary of clustered sample observation
cluster_labels <- cutree(hc, k = 4)
subset_data
subset_data$cluster_labels <- cluster_labels
View(subset_data)
# Subset the data by randomly selecting 500 observations
subset_data <- data_hc[sample(nrow(data_hc), 500), ]
# Perform hierarchical clustering on the subset data
hc <- hclust(dist(subset_data))
# Summary of clustered sample observation
cluster_labels <- cutree(hc, k = 4)
subset_data$cluster_labels <- cluster_labels
summary(subset_data$cluster_labels)
summary(subset_data[subset_data$cluster_labels==1,])
summary(subset_data[subset_data$cluster_labels==1,])
summary(subset_data[subset_data$cluster_labels==2,])
summary(subset_data[subset_data$cluster_labels==3,])
summary(subset_data[subset_data$cluster_labels==4,])
# Subset the data by randomly selecting 500 observations
subset_data <- data_hc[sample(nrow(data_hc), 500), ]
# Perform hierarchical clustering on the subset data
hc <- hclust(dist(subset_data))
cluster_labels <- cutree(hc, k = 4)
subset_data$cluster_labels <- cluster_labels
summary(subset_data[subset_data$cluster_labels==1,])
summary(subset_data[subset_data$cluster_labels==2,])
summary(subset_data[subset_data$cluster_labels==3,])
summary(subset_data[subset_data$cluster_labels==4,])
set.seed(1234)
subset_data <- data_hc[sample(nrow(data_hc), 500), ]
# Perform hierarchical clustering on the subset data
hc <- hclust(dist(subset_data))
# Summary of clustered sample observation
cluster_labels <- cutree(hc, k = 4)
subset_data$cluster_labels <- cluster_labels
summary(subset_data[subset_data$cluster_labels==1,])
summary(subset_data[subset_data$cluster_labels==2,])
summary(subset_data[subset_data$cluster_labels==3,])
summary(subset_data[subset_data$cluster_labels==4,])
# prepare data
data_cluster = data
data_cluster <- data_cluster %>%
mutate(PAY_0 = droplevels(PAY_0), PAY_2 = droplevels(PAY_2), PAY_3 = droplevels(PAY_3), PAY_4 = droplevels(PAY_4),
PAY_5 = droplevels(PAY_5), PAY_6 = droplevels(PAY_6))
# Empty vector to store WCSS values
wcss =  numeric(10)
for (k in 1:10) {
model <- kmeans(data_cluster[,-24], centers = k)
wcss[k] <- model$tot.withinss
}
plot(1:10, wcss, type = "b", xlab = "Number of clusters (k)", ylab = "Within-cluster sum of squares (WCSS)")
hist(subset_data$cluster_labels)
hist(as.facter(subset_data$cluster_labels))
hist(facter(subset_data$cluster_labels))
hist(as.factor(subset_data$cluster_labels))
subset_data$cluster_labels
summary(subset_data[subset_data$cluster_labels==1,])
plot(subset_data[subset_data$cluster_labels==1,])
summary(subset_data[subset_data$cluster_labels==1,])
gmm_model <- Mclust(data[, -24], G = 5)
gmm_model <- Mclust(data[, -24], G = 5)
# Retrieve the cluster assignments
cluster_labels <- gmm_model$classification
data_mc = data
gmm_model <- Mclust(data_mc[, -24], G = 5)
# Summary of clustered sample observation
data_mc$cluster_labels <- cluster_labels
summary(subset_data[data_mc$cluster_labels==1,])
summary(data_mc[data_mc$cluster_labels==1,])
summary(data_mc[data_mc$cluster_labels==2,])
summary(data_mc[data_mc$cluster_labels==3,])
summary(data_mc[data_mc$cluster_labels==4,])
set.seed(1234)
# prepare data
data_cluster = data
# prepare data
data_knn = data
# Empty vector to store WCSS values
wcss =  numeric(10)
for (k in 1:10) {
model <- kmeans(data_knn[,-24], centers = k)
wcss[k] <- model$tot.withinss
}
# Perform GMM clustering
library(mclust)
data_mc = data
gmm_model <- Mclust(data_mc[, -24], G = 3)
# Retrieve the cluster assignments
cluster_labels <- gmm_model$classification
# Summary of clustered sample observation
data_mc$cluster_labels <- cluster_labels
summary(data_mc[data_mc$cluster_labels==1,])
summary(data_mc[data_mc$cluster_labels==2,])
summary(data_mc[data_mc$cluster_labels==3,])
# Generate density values from the GMM
density_values <- mclust::densityMclust(gmm_model, data_mc)
summary(gmm_model)
plot(mbank,what=c("BIC"))
plot(gmm_model,what=c("BIC"))
gmm_model <- Mclust(data_mc[, -24], G = 3:10)
plot(gmm_model,what=c("BIC"))
plot(gmm_model,what=c("density"))
# try different k
plot(gmm_model,what=c("BIC"))
gmm_model <- Mclust(data_mc[, -24], G = 3:7)
gmm_model <- Mclust(data_mc[, -24], G = 3)
# Visualization
plot(gmm_model,what=c("density"))
# Subset the data by randomly selecting 500 observations
subset_data <- data_hc[sample(nrow(data_hc), 500), ]
# Subset the data by randomly selecting 500 observations
subset_data <- data_hc[sample(nrow(data_hc), 500), ]
# Perform hierarchical clustering on the subset data
hc <- hclust(dist(subset_data))
cluster_labels <- cutree(hc, k = 3)
subset_data$cluster_labels <- cluster_labels
summary(subset_data[subset_data$cluster_labels==1,])
summary(subset_data[subset_data$cluster_labels==2,])
summary(subset_data[subset_data$cluster_labels==3,])
is.nan(data_nn)
is.nan(data_kknn)
is.nan(data_knn)
is.nan(data_knn[1])
data_knn[1,]
is.nan(data_knn[,1])
data_knn[,1]
knitr::opts_chunk$set(echo = T)
knitr::opts_chunk$set(fig.height=4)
knitr::opts_chunk$set(fig.width=6)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
X = read.table("tableICA.txt")
pca_result = princomp(X, cor=T)
summary(pca_result)
pca_result$loadings
pc1 = pca_result$scores[, 1]
pc2 = pca_result$scores[, 2]
pc3 = pca_result$scores[, 3]
# plot
plot(x = pc1, y = pc2, type="n")
title(main="Original variables in PC scores")
text(pca_result$scores[,1:2], labels=(rownames(X)), cex=.8)
# screeplot
screeplot(pca_result, type="l")
# PCA components
library(fastICA)
ica = fastICA(X,3)
par(mfrow=c(2,3))
hist(ica$S[,1], xlim=c(-5,5))
hist(ica$S[,2], xlim=c(-5,5))
hist(ica$S[,3], xlim=c(-5,5))
hist(pc1, xlim=c(-5,5), ylim=c(0,120))
hist(pc2, xlim=c(-5,5), ylim=c(0,120))
hist(pc3, xlim=c(-5,5), ylim=c(0,120))
par(mfrow=c(1,3))
plot(pc1)
plot(pc2)
plot(pc3)
# prepare data
data_knn = data
data_knn <- data_knn %>%
mutate(PAY_0 = droplevels(PAY_0), PAY_2 = droplevels(PAY_2), PAY_3 = droplevels(PAY_3), PAY_4 = droplevels(PAY_4),
PAY_5 = droplevels(PAY_5), PAY_6 = droplevels(PAY_6))
# Empty vector to store WCSS values
wcss =  numeric(10)
is.nan(data_knn[,1])
is.nan(data_knn[,1])
1
for (k in 1:10) {
model <- kmeans(data_knn[,-24], centers = k)
wcss[k] <- model$tot.withinss
}
plot(1:10, wcss, type = "b", xlab = "Number of clusters (k)", ylab = "Within-cluster sum of squares (WCSS)")
data = read_excel("default_of_credit_card_clients.xls", skip = 1)
data = data[,-1] # remove ID
colnames(data)[24] = "default"
# Remove education indices which are not defined
data <- data %>% filter(EDUCATION<=4 & EDUCATION>0)
# Remove MARRIAGE indices which are not defined
data <- data %>% filter(MARRIAGE!=0)
for(i in 6:11){
# -2 is not defined in the document
data <- data[data[,i]!=-2,]
# index pay duly as 0
data[data[,i]==-1,i] <- 0
}
data_knn = data
# factorize
data <- data %>%
mutate(SEX = factor(SEX, labels = c("Male", "Female")), EDUCATION = factor(EDUCATION), MARRIAGE = factor(MARRIAGE)) %>%
mutate(EDUCATION = car::recode(EDUCATION, "c(0, 4, 5, 6) = 'Other';  1 = 'Grad.School'; 2 = 'University'; 3 = 'High.School'"),
MARRIAGE = car::recode(MARRIAGE, "c(0, 3) = 'Other'; 1 = 'Married'; 2 = 'Single'"),
default = factor(default, levels = c(0, 1), labels = c("No", "Yes")))
data = data %>%
mutate(PAY_0 = factor(PAY_0, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_2 = factor(PAY_2, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_3 = factor(PAY_3, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_4 = factor(PAY_4, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_5 = factor(PAY_5, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_6 = factor(PAY_6, order=TRUE,levels=c(seq(0,9, by = 1))))
set.seed(1234)
# split data
idx = sample(1:nrow(data), size=nrow(data)*0.8, replace = FALSE)
train_data = data[idx,]
test_data = data[-idx,]
data_knn <- data_knn %>%
mutate(PAY_0 = droplevels(PAY_0), PAY_2 = droplevels(PAY_2), PAY_3 = droplevels(PAY_3), PAY_4 = droplevels(PAY_4),
PAY_5 = droplevels(PAY_5), PAY_6 = droplevels(PAY_6))
# Empty vector to store WCSS values
wcss =  numeric(10)
for (k in 1:10) {
model <- kmeans(data_knn[,-24], centers = k)
wcss[k] <- model$tot.withinss
}
plot(1:10, wcss, type = "b", xlab = "Number of clusters (k)", ylab = "Within-cluster sum of squares (WCSS)")
data_kmeans = data
for (k in 1:10) {
model <- kmeans(data_kmeans[,-24], centers = k)
wcss[k] <- model$tot.withinss
}
View(data_kmeans)
# find elbow, k=4 is appropriate
kmeans = kmeans(data_means[,-24], centers = 5)
# find elbow, k=4 is appropriate
kmeans = kmeans(data_kmeans[,-24], centers = 5)
data_kmeans[,-24]
# find elbow, k=4 is appropriate
kmeans = kmeans(data_kmeans[,-24], centers = 5)
# find elbow, k=4 is appropriate
kmeans = kmeans(na.omit(data_kmeans[,-24]), centers = 5)
na.omit(data_kmeans[,-24])
View(data)
model <- kmeans(data_kmeans[,c(1,5,12:23)], centers = k)
# prepare data
data_kmeans = data[,c(1,5,12:23)]
# Empty vector to store WCSS values
wcss =  numeric(10)
for (k in 1:10) {
model <- kmeans(data_kmeans[,c(1,5,12:23)], centers = k)
wcss[k] <- model$tot.withinss
}
# Empty vector to store WCSS values
wcss =  numeric(10)
for (k in 1:10) {
model <- kmeans(data_kmeans, centers = k)
wcss[k] <- model$tot.withinss
}
plot(1:10, wcss, type = "b", xlab = "Number of clusters (k)", ylab = "Within-cluster sum of squares (WCSS)")
wcss
# find elbow, k=4 is appropriate
kmeans = kmeans(data_kmeans, centers = 5)
kmeans$cluster
# find elbow, k=4 is appropriate
kmeans = kmeans(data_kmeans, centers = 5)
subset_data$cluster_labels <- cluster_labels
# find elbow, k=4 is appropriate
kmeans_result = kmeans(data_kmeans, centers = 5)
summary(kmeans_result)
summary(kmeans_result$cluster)
summary(kmeans_result)$cluster
summary(kmeans_result)
kmeans_result
## Libraries and Importing the data
library(tidyverse)
library(readxl)
library(ggplot2)
library(glmnet)
library(scales)
library(mclust)
library(knitr)
library(pander)
library(mclust)
library(kableExtra)
data = read_excel("default_of_credit_card_clients.xls", skip = 1)
data = data[,-1] # remove ID
# Remove education indices which are not defined
data <- data %>% filter(EDUCATION<=4 & EDUCATION>0)
# Remove MARRIAGE indices which are not defined
data <- data %>% filter(MARRIAGE!=0)
for(i in 6:11){
# -2 is not defined in the document + index pay duly as 0
data <- data[data[,i]!=-2,]
data[data[,i]==-1,i] <- 0
}
colnames(data)[24] <- 'default'
data <- data %>%
mutate(SEX = factor(SEX, labels = c("Male", "Female")),
EDUCATION = factor(EDUCATION),
MARRIAGE = factor(MARRIAGE)) %>%
mutate(EDUCATION = car::recode(EDUCATION, "c(0, 4, 5, 6) = 'Other';  1 = 'Grad.School'; 2 = 'University'; 3 = 'High.School'"),
MARRIAGE = car::recode(MARRIAGE, "c(0, 3) = 'Other'; 1 = 'Married'; 2 = 'Single'"),
default = factor(default, levels = c(0, 1), labels = c("No", "Yes")))
data <- data %>%
mutate(PAY_0 = factor(PAY_0, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_2 = factor(PAY_2, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_3 = factor(PAY_3, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_4 = factor(PAY_4, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_5 = factor(PAY_5, order=TRUE,levels=c(seq(0,9, by = 1))),
PAY_6 = factor(PAY_6, order=TRUE,levels=c(seq(0,9, by = 1))))
# set.seed for sampling
set.seed(12345)
library(tree)
start.time = Sys.time()
for (i in c(2:4, 6:11)){
data2[, i] = factor(data2[,i])
}
library(gridExtra)
library(grid)
data2 <- data
colnames(data2)[6] <- 'September'
colnames(data2)[7] <- 'August'
colnames(data2)[8] <- 'July'
colnames(data2)[9] <- 'June'
colnames(data2)[10] <- 'May'
colnames(data2)[11] <- 'April'
pay_0 <- ggplot(data2, aes(x = September)) + geom_bar() + theme_loan()
data2 <- read.csv("default_of_credit_card_clients.csv", skip = 1)
data2 <- data2[,-1] # remove ID
colnames(data2)[24] <- "default"
# Remove education indices which are not defined
data2 <- data2 %>% filter(EDUCATION<=4 & EDUCATION>0)
# Remove MARRIAGE indices which are not defined
data2 <- data2 %>% filter(MARRIAGE!=0)
for(i in 6:11){
# -2 is not defined in the document
data2 <- data2[data2[,i]!=-2,]
# index pay duly as 0
data2[data2[,i]==-1,i] <- 0
}
x = data2[,-(ncol(data2))]
y = data2$default
## Selecting the data
for (i in c(2:4,6:11)){
data2[, i] = factor(data2[,i])
}
## turn x into dummy variable
x = cbind(x[,-c(2:4,6:11)],fastDummies::dummy_cols(data[,c(2:4,6:11)]))
for (i in c(1:ncol(x))){x[,i] = as.numeric(x[,i])}
#function for collecting results
pred_res_func = function(pred_data){
pred_res = rep(NA, nrow(pred_data))
for (i in 1:nrow(pred_data)){
if (pred_data[i,1]>pred_data[i,2]){pred_res[i]=0}
else{pred_res[i]=1}
}
return(pred_res)
}
start.time = Sys.time()
for (i in c(2:4, 6:11)){
data2[, i] = factor(data2[,i])
}
tree_model.1 = tree(factor(default) ~ ., data=data2, mincut=1)
end.time = Sys.time()
tree_noncv.time = end.time - start.time
start.time = Sys.time()
tree_cvmodel = cv.tree(tree_model.1, K=10)
tree_size_res = matrix(tree_cvmodel$dev,1,length(tree_cvmodel$dev), byrow=T)
colnames(tree_size_res) = as.character(tree_cvmodel$size)
rownames(tree_size_res) = c("deviance")
pander(tree_size_res)
tree_model.2 = prune.tree(tree_model.1, best=4)
plot(tree_model.2)
text(tree_model.2, cex=.75, font=2)
tree_model.pred = predict(tree_model.2, data)
tree_model.pred_res = pred_res_func(tree_model.pred)
tree_model.accuracy = 1 - (length(which(tree_model.pred_res != data$default))/nrow(data))
end.time = Sys.time()
tree_cv.time = end.time - start.time
library(randomForest)
rf_model = randomForest(factor(default) ~ ., data=data, ntree = 100, nodesize = 10) #ntree = 100(b/c computational issue)
rf_model.pred = predict(rf_model, data)
rf_model.accuracy = 1 - (length(which(rf_model.pred != data$default))/nrow(data))
# - if we split into training and testing set
start.time = Sys.time()
train_idx = sample(1:nrow(data), 0.7 * nrow(data))  # 70% for training
train_data = data[train_idx, ]
test_data = data[-train_idx, ]
rf_spmodel = randomForest(factor(default) ~ ., data=train_data, ntree = 100, nodesize = 10)
rf_spmodel.pred = predict(rf_spmodel, test_data)
rf_spmodel.accuracy = 1 - (length(which(rf_spmodel.pred != test_data$default))/nrow(test_data))
# it still looks good.
end.time = Sys.time()
rf.time = end.time - start.time
library(neuralnet)
install.packages("neuralnet")
library(neuralnet)
start.time = Sys.time()
data_matrix = model.matrix(
~ LIMIT_BAL + SEX + EDUCATION + MARRIAGE + AGE + PAY_0 + PAY_2 + PAY_3 + PAY_4 + PAY_5 + PAY_6 + BILL_AMT1 + BILL_AMT2 + BILL_AMT3 + BILL_AMT4 + BILL_AMT5 + BILL_AMT6 + PAY_AMT1 + PAY_AMT2 + PAY_AMT3 + PAY_AMT4 + PAY_AMT5 + PAY_AMT6 + default,
data = data2)
train_data_matrix = data_matrix[train_idx, ]
test_data_matrix = data_matrix[-train_idx, ]
n = colnames(train_data_matrix[,-1])
f = as.formula(paste("factor(default) ~", paste(n[!n %in% "default"], collapse = " + ")))
nn_model = neuralnet(f, data = train_data_matrix,
hidden = 5,
threshold = 0.01,
linear.output = T)
nn_model.pred = predict(nn_model, test_data_matrix)
nn_model.pred_res = pred_res_func(nn_model.pred)
nn_model.accuracy = 1 - (length(which(nn_model.pred_res != test_data$default))/nrow(test_data_matrix))
end.time = Sys.time()
nn.time = end.time - start.time
gc()
